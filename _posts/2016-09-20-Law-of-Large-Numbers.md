---
layout: post 
title: "대수의 법칙"
author: "JKKim"
date: "September 20, 2016"

output: html_document
#categories: [statistics]
#tags:[Law of Large Numbers]
---

## 예제 


우생학의 창시자로 알려진 프랜시스 골턴(Francsis Galton)의 에피소드는 집단지성의 위력을 이야기할 때 종종 인용됩니다. 골턴은 1906년 우연히 우시장에서 황소 무게를 눈대중으로 알아맞히는 대회를 구경하는데 이 대회에는 무려 800여 명이 참가했는데 그 누구도 황소 무게를 정확히 맞히지 못했다고 합니다.

하지만 놀라운 것은 대회 참가자들이 적어낸 무게의 평균을 계산해본 결과 황소의 실제무게와 거의 비슷했다는 것이다. 추정 평균치는 1197파운드였고 황소의 실제 무게는 1198파운드였다고 합니다. 황소 전문가들이 써낸 추정치보다 전체 참가자 추정치의 평균값이 더 정확했던 것입니다.

골턴은 이 이해할 수 없는 놀라운 이야기를 1907년 과학저널 ‘네이처’에 발표합니다. 개별적인 한 사람 한 사람의 지식이나 지혜는 미미해보일지라도 그것이 모이면 누구도 예상 못한 놀라운 힘을 발휘할 수 있음을 시사해주는 것입니다.


## 풀이  

각 개인의 황소 몸무게 예측치를 $Y_i$ 라고 표현하고 황소의 몸무게 참값을 $\mu$ 라고 한다면 각 개인 추정치의 오차는 $e_i = y_i - \mu$ 로 표현될 것입니다. 어떤 사람은 황소 몸무게를 지나치게 크게 추정하여 $e_i$ 값이 양의 값을 갖게 되고 또 어떤 사람은 황소 몸무게를 작게 추정하여 $e_i$ 값이 음의 값을 갖게 되겠지만 평균적으로는 $E(e_i)=0$ 이라고 볼수 있을 것입니다. (즉, 사람들의 예측에 편향이 없다고 볼수 있을 것입니다. ) 그러한 경우에는 표본 평균이 참값에 확률적으로 수렴합니다. 
즉, $\bar{Y}_n=n^{-1} \sum_{i=1}^n Y_i$과 참값 $\mu$ 과의 차이를 표본 평균의 오차라고 한다면 이 오차는 표본수가 커질수록 확률적으로 0 에 수렴합니다. 이를 대수의 법칙이라고 합니다. 이러한 대수의 법칙을 수식으로 표현하면 다음과 같습니다. 
$$ \lim_{n \rightarrow \infty} P \left\{ \left| \bar{Y}_n - \mu \right| > \epsilon  \right\} = 0 ,  \  \  \mbox{for any }\epsilon >0. $$



이를 좀더 알아보기 위하여 0.5 의 확률로 1 또는 0 의 값을 갖는 베르누이 확률변수 Y 를 n=1000 개 독립적으로  발생시킨후 각 $t=1,2, \cdots, n$ 에 대해서 $\bar{Y}_t=\sum_{i=1}^t y_i / t$ 를 계산한후 이를 $Y$ 축으로 놓고 $t$ 값을 $X$ 축에 놓아 그래프를 그려보면 다음과 같이 나옵니다. 


![](rplot02.png)

처음 표본수가 낮은 경우에는 어느 정도 변동이 있지만 표본수 $n$이 증가하면서 표본평균 값이 0.5 를 중심으로 크게 변하지 않음을 알수 있습니다. 



## 토론

1. 대수의 법칙은 체비세프 부등식을 이용해서 쉽게 구할수 있습니다. 체비세프 부등식을 사용하면 
$$ P \left\{ \left| \bar{Y}_n - \mu \right| > \epsilon  \right\} \le \frac{E\{ \left| \bar{Y}_n - \mu \right|^2 \}  }{\epsilon^2}
$$
이 얻어지는데 $E(Y_i)=\mu$ 이 성립하면 위 식의 오른쪽 항은 $Var ( \bar{Y}_n)/ \epsilon^2$ 이 되고  이 분산은 $Y_i$ 들이 서로 독립인 경우에 분산이 $\sigma^2/n$이 되어 따라서 $n$이 증가함에 따라 0으로 수렴하게 되므로 위 식의 오른쪽도 0 으로 수렴하게 되는 것입니다. 

2. 
대수의 법칙을 처음 발견한 사람은 야곱 베르누이 입니다. 그는 체비세프 보다 100년 넘게 앞서 살았던 사람이었으므로 체비세프 부등식을 이용한 증명을 하지 못하고 $Y_i$ 가 지시변수인 경우 $\sum_{i=1}^n Y_i$ 의 분포가 이항분포를 따른다는 것을 이용하여  이를 바탕으로 복잡하게 증명을 완성했습니다. 그래서 그의 이름을 따서 $Y$ 가 1 또는 0의 값을 갖는 확률 분포를 베르누이 분포라고 부릅니다. 




3. 대수의 법칙이 가장 많이 사용되는 분야는 아마도 몬테 카를로 계산일 것입니다. 몬테 카를로 계산법은  원하는 모수(parameter)를 $\mu = E(X)$ 의 형태로 표현한후 시뮬레이션을 통해 $X_i$ 들을 아주 많이 발생시킨 후 이들의 표본 평균으로 근사하는 방법입니다. 조건부 확률같은 확률 역시 일종의 평균 이므로 몬테 카를로 시뮬레이션을 통해서 근사적으로 구현할수 있습니다. 이 몬테 카를로 계산은 컴퓨터의 발달과 함께 통계학의 적용 범위를 급격히 넓혀준 유용한 기법이며 그것의 이론적 근거는 대수의 법칙입니다. 




4. 대수의 법칙과 관련하여 흥미로운 것은 표본수가 2배 증가한다고 해도 정확도가 2배 증가하는 것이 아니라 2의 제곱근인 1.414 배만큼 증가한다는 것입니다. 표본수가 $n$에서 $2n$ 이 되면 표본평균의 표준  오차가 $\sigma/\sqrt{n}$ 에서 $\sigma/\sqrt{2n}$ 으로 $\sqrt{2}$ 만큼 줄어듭니다. 따라서 비용은 표본수에 비례해서 증가하지만 그에 따른 효용은 그의 제곱근에 비례해서 증가하게 되므로 적절한 수준에서 비용과 효용을 고려한 표본수를 결정할 필요가 있습니다. 

5. 아래 그래프는 두개의 베르누이 변수로부터 각각 표본 평균을 구한후 그것들의 오차가 얼마나 빨리 0으로 수렴하는가를 보여주는 그래프입니다. $Y$는 Bernoulli (0.5) 분포로 부터 발생했지만 $Z$는 Bernoulli (0.1) 분포로부터 발생했습니다. 이 그래프로부터 확인할수 있듯이 $Y$의 평균보다는 $Z$의 평균이 더 빨리 모평균에 가깝게 수렴합니다. 그 이유는 $V(Y)=0.5 *0.5=0.25$ 이지만 $V(Z)=0.9*0.1=0.09$ 이므로 $\bar{Y}_n$ 의 분산이 $\bar{Z}_n$의 분산보다 크기 때문입니다. 




![](rplot03.png)











